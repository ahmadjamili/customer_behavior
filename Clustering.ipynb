{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c770397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('orders.csv')\n",
    "temp_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dd05b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Preprocessor : \n",
    "    def __init__ (self, df):\n",
    "        self.df = df.copy()\n",
    "        self.k=5\n",
    "        self.original_df = df.copy()\n",
    "    def handle_missing_values (self) :\n",
    "        self.df.fillna(0, inplace=True)\n",
    "      \n",
    "    def transform (self) : \n",
    "        self.handle_missing_values()\n",
    "        self.time_series()\n",
    "        self.rare_label_encoding()\n",
    "        self.min_max_scaler()\n",
    "        self.submission_df_full = pd.merge(self.original_df['ID_Customer'] , self.df, on='ID_Customer', how='left')\n",
    "        self.drop_columns()\n",
    "        return self.submission_df_full\n",
    "    \n",
    "    def drop_columns(self) :\n",
    "        self.submission_df_full.drop(columns=['ID_Customer'],inplace=True)\n",
    "        \n",
    "    def rare_label_encoding(self):\n",
    "        top_k_labels = self.df['city_name_fa'].value_counts().nlargest(self.k).index.tolist()\n",
    "        \n",
    "        self.city_map = {label: i + 1 for i, label in enumerate(top_k_labels)}\n",
    "        \n",
    "        self.df['city_encoded'] = self.df['city_name_fa'].apply(lambda x: self.city_map.get(x, self.k + 1))\n",
    "        \n",
    "        self.df.drop(columns=['city_name_fa'], inplace=True)\n",
    "        \n",
    "    def min_max_scaler(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.df[['Amount_Gross_Order','Recency']] = scaler.fit_transform(self.df[['Amount_Gross_Order','Recency']])        \n",
    "    \n",
    "    def time_series(self):\n",
    "        self.df['DateTime_CartFinalize'] = pd.to_datetime(self.df['DateTime_CartFinalize'])\n",
    "\n",
    "        latest_date = self.df['DateTime_CartFinalize'].max()\n",
    "        last_order = self.df.groupby('ID_Customer')['DateTime_CartFinalize'].max()\n",
    "        recency = (latest_date - last_order).dt.days\n",
    "        recency = recency.reset_index().rename(columns={'DateTime_CartFinalize': 'Recency'})\n",
    "\n",
    "        customer_df = self.df.groupby('ID_Customer').agg(\n",
    "            last_order=('DateTime_CartFinalize', 'max'),\n",
    "            first_order=('DateTime_CartFinalize', 'min'),\n",
    "            order_count=('DateTime_CartFinalize', 'count')\n",
    "        )\n",
    "\n",
    "        customer_df['last_order'] = pd.to_datetime(customer_df['last_order'])\n",
    "        customer_df['first_order'] = pd.to_datetime(customer_df['first_order'])\n",
    "\n",
    "        total_days = (customer_df['last_order'] - customer_df['first_order']).dt.days\n",
    "        customer_df['frequency_per_month'] = customer_df['order_count'] / (total_days +5 + 1e-6)\n",
    "        customer_df=customer_df.reset_index()\n",
    "        customer_df.drop(columns = ['first_order','last_order','order_count'],inplace=True)\n",
    "        \n",
    "        # a dataframe with CUSTOMER_ID and RECENCY and FREQUENCY\n",
    "        together_df = customer_df.merge(recency, on='ID_Customer' , how = 'inner')\n",
    "        # a dataframe with ID_CUSTOMER and QUANTITY_ITEM\n",
    "        df2 = self.df.groupby('ID_Customer')['Quantity_item'].sum().reset_index()\n",
    "        # a dataframe with ID_CUSTOMER and AMOUNT_GROSS_Order\n",
    "        df3 = self.df.groupby('ID_Customer')['Amount_Gross_Order'].sum().reset_index()\n",
    "        # a dataframe with ID_CUSTOMER and city_name_fa\n",
    "        df_unique = self.df.drop_duplicates(subset='ID_Customer', keep='first')\n",
    "        df_unique.drop(columns = ['ID_Order','ID_Item','DateTime_CartFinalize','Amount_Gross_Order','Quantity_item'] , inplace=True)\n",
    "        alltogether_df = together_df.merge(df2,on='ID_Customer',how='inner')\n",
    "        alltogether_df = alltogether_df.merge(df3,on='ID_Customer',how='inner')\n",
    "        alltogether_df=alltogether_df.merge(df_unique , on='ID_Customer',how='inner')\n",
    "        self.df = alltogether_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b24865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessor.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Preprocessor : \n",
    "    def __init__ (self, df):\n",
    "        self.df = df.copy()\n",
    "        self.k=5\n",
    "        self.original_df = df.copy()\n",
    "    def handle_missing_values (self) :\n",
    "        self.df.fillna(0, inplace=True)\n",
    "      \n",
    "    def transform (self) : \n",
    "        self.handle_missing_values()\n",
    "        self.time_series()\n",
    "        self.rare_label_encoding()\n",
    "        self.min_max_scaler()\n",
    "        self.submission_df_full = pd.merge(self.original_df['ID_Customer'] , self.df, on='ID_Customer', how='left')\n",
    "        self.drop_columns()\n",
    "        return self.submission_df_full\n",
    "    \n",
    "    def drop_columns(self) :\n",
    "        self.submission_df_full.drop(columns=['ID_Customer'],inplace=True)\n",
    "        \n",
    "    def rare_label_encoding(self):\n",
    "        top_k_labels = self.df['city_name_fa'].value_counts().nlargest(self.k).index.tolist()\n",
    "        \n",
    "        self.city_map = {label: i + 1 for i, label in enumerate(top_k_labels)}\n",
    "        \n",
    "        self.df['city_encoded'] = self.df['city_name_fa'].apply(lambda x: self.city_map.get(x, self.k + 1))\n",
    "        \n",
    "        self.df.drop(columns=['city_name_fa'], inplace=True)\n",
    "        \n",
    "    def min_max_scaler(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.df[['Amount_Gross_Order','Recency']] = scaler.fit_transform(self.df[['Amount_Gross_Order','Recency']])        \n",
    "    \n",
    "    def time_series(self):\n",
    "        self.df['DateTime_CartFinalize'] = pd.to_datetime(self.df['DateTime_CartFinalize'])\n",
    "\n",
    "        latest_date = self.df['DateTime_CartFinalize'].max()\n",
    "        last_order = self.df.groupby('ID_Customer')['DateTime_CartFinalize'].max()\n",
    "        recency = (latest_date - last_order).dt.days\n",
    "        recency = recency.reset_index().rename(columns={'DateTime_CartFinalize': 'Recency'})\n",
    "\n",
    "        customer_df = self.df.groupby('ID_Customer').agg(\n",
    "            last_order=('DateTime_CartFinalize', 'max'),\n",
    "            first_order=('DateTime_CartFinalize', 'min'),\n",
    "            order_count=('DateTime_CartFinalize', 'count')\n",
    "        )\n",
    "\n",
    "        customer_df['last_order'] = pd.to_datetime(customer_df['last_order'])\n",
    "        customer_df['first_order'] = pd.to_datetime(customer_df['first_order'])\n",
    "\n",
    "        total_days = (customer_df['last_order'] - customer_df['first_order']).dt.days\n",
    "        customer_df['frequency_per_month'] = customer_df['order_count'] / (total_days +5 + 1e-6)\n",
    "        customer_df=customer_df.reset_index()\n",
    "        customer_df.drop(columns = ['first_order','last_order','order_count'],inplace=True)\n",
    "        \n",
    "        # a dataframe with CUSTOMER_ID and RECENCY and FREQUENCY\n",
    "        together_df = customer_df.merge(recency, on='ID_Customer' , how = 'inner')\n",
    "        # a dataframe with ID_CUSTOMER and QUANTITY_ITEM\n",
    "        df2 = self.df.groupby('ID_Customer')['Quantity_item'].sum().reset_index()\n",
    "        # a dataframe with ID_CUSTOMER and AMOUNT_GROSS_Order\n",
    "        df3 = self.df.groupby('ID_Customer')['Amount_Gross_Order'].sum().reset_index()\n",
    "        # a dataframe with ID_CUSTOMER and city_name_fa\n",
    "        df_unique = self.df.drop_duplicates(subset='ID_Customer', keep='first')\n",
    "        df_unique.drop(columns = ['ID_Order','ID_Item','DateTime_CartFinalize','Amount_Gross_Order','Quantity_item'] , inplace=True)\n",
    "        alltogether_df = together_df.merge(df2,on='ID_Customer',how='inner')\n",
    "        alltogether_df = alltogether_df.merge(df3,on='ID_Customer',how='inner')\n",
    "        alltogether_df=alltogether_df.merge(df_unique , on='ID_Customer',how='inner')\n",
    "        self.df = alltogether_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "103ffca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_8548\\1939181444.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.drop(columns = ['ID_Order','ID_Item','DateTime_CartFinalize','Amount_Gross_Order','Quantity_item'] , inplace=True)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(df)\n",
    "X = preprocessor.transform()\n",
    "customer_df =X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a104cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_CLUSTERS = 3\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=N_CLUSTERS , random_state=42 , n_init = 10)\n",
    "customer_df['Cluster']=model.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b568faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cluster\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "...         ...\n",
       "199995        0\n",
       "199996        0\n",
       "199997        0\n",
       "199998        0\n",
       "199999        0\n",
       "\n",
       "[200000 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(customer_df['Cluster'])\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc9560",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazirmatn\" color=\"#0099cc\">\n",
    "معیار ارزیابی\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazirmatn\" size=3>\n",
    "    معیاری که برای ارزیابی عملکرد مدل انتخاب کرده‌ایم، <code>silhouette score</code> نام دارد.\n",
    "    <br>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e1cb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_8548\\1939181444.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.drop(columns = ['ID_Order','ID_Item','DateTime_CartFinalize','Amount_Gross_Order','Quantity_item'] , inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette score using existing data and cluster labels\n",
    "sil_score = silhouette_score(Preprocessor(pd.read_csv('orders.csv')).transform(),pd.read_csv('submission.csv').Cluster)\n",
    "print(f'Silhouette Score: {sil_score:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "462b8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.46149668904134\n"
     ]
    }
   ],
   "source": [
    "print( 100 * (sil_score + 1 ) / 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2e32764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['Clustering.ipynb', 'submission.csv', 'model', 'preprocessor.py']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "joblib.dump(model, 'model')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['Clustering.ipynb', 'submission.csv', 'model', 'preprocessor.py']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829579c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
